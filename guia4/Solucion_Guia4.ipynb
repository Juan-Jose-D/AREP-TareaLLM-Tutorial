{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (2.6.1)\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (1.2.1)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
      "  Downloading langchain_core-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading langsmith-0.4.38-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading ormsgpack-1.11.0-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading orjson-3.11.4-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Downloading regex-2025.10.23-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\juan.dgomez\\documents\\ejercicioia\\guia4\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading langchain-1.0.2-py3-none-any.whl (107 kB)\n",
      "Downloading langchain_core-1.0.1-py3-none-any.whl (467 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langsmith-0.4.38-py3-none-any.whl (397 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_openai-1.0.1-py3-none-any.whl (81 kB)\n",
      "Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/879.4 kB ? eta -:--:--\n",
      "   ---------------------- --------------- 524.3/879.4 kB 645.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 786.4/879.4 kB 884.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 786.4/879.4 kB 884.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 786.4/879.4 kB 884.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 786.4/879.4 kB 884.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 879.4/879.4 kB 454.2 kB/s  0:00:01\n",
      "Downloading orjson-3.11.4-cp311-cp311-win_amd64.whl (131 kB)\n",
      "Downloading ormsgpack-1.11.0-cp311-cp311-win_amd64.whl (112 kB)\n",
      "Downloading regex-2025.10.23-cp311-cp311-win_amd64.whl (277 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, xxhash, tenacity, regex, ormsgpack, orjson, jsonpatch, tiktoken, requests-toolbelt, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain\n",
      "\n",
      "   ---- -----------------------------------  2/17 [tenacity]\n",
      "   ------- --------------------------------  3/17 [regex]\n",
      "   ---------------- -----------------------  7/17 [tiktoken]\n",
      "   ------------------ ---------------------  8/17 [requests-toolbelt]\n",
      "   ------------------ ---------------------  8/17 [requests-toolbelt]\n",
      "   --------------------- ------------------  9/17 [langsmith]\n",
      "   --------------------- ------------------  9/17 [langsmith]\n",
      "   --------------------- ------------------  9/17 [langsmith]\n",
      "   --------------------- ------------------  9/17 [langsmith]\n",
      "   --------------------- ------------------  9/17 [langsmith]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ---------------------------- ----------- 12/17 [langgraph-checkpoint]\n",
      "   ------------------------------ --------- 13/17 [langchain-openai]\n",
      "   ------------------------------ --------- 13/17 [langchain-openai]\n",
      "   ----------------------------------- ---- 15/17 [langgraph]\n",
      "   ----------------------------------- ---- 15/17 [langgraph]\n",
      "   ----------------------------------- ---- 15/17 [langgraph]\n",
      "   ----------------------------------- ---- 15/17 [langgraph]\n",
      "   ------------------------------------- -- 16/17 [langchain]\n",
      "   ------------------------------------- -- 16/17 [langchain]\n",
      "   ---------------------------------------- 17/17 [langchain]\n",
      "\n",
      "Successfully installed jsonpatch-1.33 langchain-1.0.2 langchain-core-1.0.1 langchain-openai-1.0.1 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 langsmith-0.4.38 orjson-3.11.4 ormsgpack-1.11.0 regex-2025.10.23 requests-toolbelt-1.0.0 tenacity-9.1.2 tiktoken-0.12.0 xxhash-3.6.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain python-dotenv langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente LangChain con OpenAI inicializado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()  # Cargar archivo .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"No se encontró la clave OPENAI_API_KEY en el archivo .env\")\n",
    "\n",
    "# Crear cliente LangChain con OpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "print(\"Cliente LangChain con OpenAI inicializado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El aprendizaje automático es una rama de la inteligencia artificial que permite a las computadoras aprender y mejorar su rendimiento en tareas específicas a partir de datos sin ser programadas explícitamente. Utiliza algoritmos y modelos estadísticos para identificar patrones y hacer predicciones basadas en la información proporcionada.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize the LLM (uses your OpenAI API key from environment)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# Create a simple prompt\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica en dos frases el concepto de {tema}.\"\n",
    ")\n",
    "\n",
    "# Combine the components using LCEL (LangChain Expression Language)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run it\n",
    "result = chain.invoke({\"tema\": \"aprendizaje automático\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleSequentialChain\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Primer paso: obtener una descripción\u001b[39;00m\n\u001b[32m      4\u001b[39m primer_prompt = PromptTemplate(\n\u001b[32m      5\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33mtema\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m     template=\u001b[33m\"\u001b[39m\u001b[33mExplica brevemente el concepto de \u001b[39m\u001b[38;5;132;01m{tema}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.chains'"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# Primer paso: obtener una descripción\n",
    "primer_prompt = PromptTemplate(\n",
    "    input_variables=[\"tema\"],\n",
    "    template=\"Explica brevemente el concepto de {tema}.\"\n",
    ")\n",
    "primer_chain = LLMChain(llm=llm, prompt=primer_prompt)\n",
    "\n",
    "# Segundo paso: generar aplicación educativa\n",
    "segundo_prompt = PromptTemplate(\n",
    "    input_variables=[\"concepto\"],\n",
    "    template=\"Propón una aplicación educativa del siguiente concepto: {concepto}.\"\n",
    ")\n",
    "segundo_chain = LLMChain(llm=llm, prompt=segundo_prompt)\n",
    "\n",
    "# Combinar ambos pasos en una cadena secuencial\n",
    "chain_secuencial = SimpleSequentialChain(chains=[primer_chain, segundo_chain])\n",
    "\n",
    "# Ejecutar la cadena completa\n",
    "resultado = chain_secuencial.run(\"realidad aumentada\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Aplicación Educativa: \"Explora el Mundo con RA\"**\n",
      "\n",
      "**Descripción General:**\n",
      "\"Explora el Mundo con RA\" es una aplicación educativa diseñada para estudiantes de educación primaria y secundaria que utiliza la realidad aumentada para enriquecer el aprendizaje de diversas materias como historia, biología, geografía y ciencias. La aplicación permite a los estudiantes interactuar con contenido educativo de manera dinámica y envolvente, facilitando una comprensión más profunda de los conceptos.\n",
      "\n",
      "**Características de la Aplicación:**\n",
      "\n",
      "1. **Exploración de Lugares Históricos:**\n",
      "   - Los estudiantes pueden apuntar su dispositivo a imágenes de monumentos o lugares históricos en libros de texto o en su entorno físico.\n",
      "   - La RA superpone información adicional, como hechos históricos, reconstrucciones 3D de cómo era el lugar en el pasado, y personajes históricos que narran su historia.\n",
      "\n",
      "2. **Lecciones de Biología Interactivas:**\n",
      "   - Al escanear imágenes de flora y fauna en libros o en el aula, los estudiantes pueden visualizar modelos 3D de los organismos.\n",
      "   - La aplicación proporciona información sobre la estructura, función y hábitat de cada organismo, así como videos cortos que muestran su comportamiento en su entorno natural.\n",
      "\n",
      "3. **Geografía Aumentada:**\n",
      "   - Al escanear un mapa físico, los estudiantes pueden ver superposiciones de datos geográficos, como poblaciones, climas y características geológicas.\n",
      "   - Se pueden realizar actividades interactivas, como quizzes geográficos en tiempo real, donde los estudiantes responden preguntas sobre el mapa que están viendo.\n",
      "\n",
      "4. **Ciencias Físicas y Químicas:**\n",
      "   - Los estudiantes pueden realizar experimentos virtuales al apuntar su dispositivo hacia un kit de laboratorio físico.\n",
      "   - La RA muestra instrucciones paso a paso y visualizaciones de las reacciones químicas o físicos que están llevando a cabo, promoviendo el aprendizaje práctico sin riesgos.\n",
      "\n",
      "5. **Gamificación:**\n",
      "   - La aplicación incluye desafíos y juegos que los estudiantes pueden completar al escanear diferentes objetos o lugares, ganando puntos y recompensas virtuales.\n",
      "   - Los estudiantes pueden formar equipos y competir en desafíos grupales que fomentan la colaboración y el aprendizaje social.\n",
      "\n",
      "**Beneficios:**\n",
      "\n",
      "- **Interactividad:** La RA convierte el aprendizaje pasivo en una experiencia activa, donde los estudiantes pueden interactuar con el contenido de manera directa.\n",
      "- **Motivación:** La inclusión de elementos de juego y la naturaleza visual de la RA mantienen a los estudiantes comprometidos y motivados para aprender.\n",
      "- **Accesibilidad:** La aplicación puede ser utilizada en aulas, en casa o en excursiones, facilitando el aprendizaje en diferentes contextos.\n",
      "- **Personalización:** Los estudiantes pueden avanzar a su propio ritmo y explorar temas que les interesen más, promoviendo un aprendizaje autodirigido.\n",
      "\n",
      "**Implementación:**\n",
      "La aplicación se puede implementar en escuelas, donde los profesores pueden integrarla en sus lecciones, así como en programas extracurriculares y en casa para complementar el aprendizaje. Además, se pueden realizar talleres para capacitar a los docentes en el uso efectivo de la tecnología.\n",
      "\n",
      "\"Explora el Mundo con RA\" representa una forma innovadora de aprender, aprovechando la tecnología para hacer que la educación sea más interactiva, accesible y divertida.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "# Crear el modelo LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# Primer paso: obtener una descripción\n",
    "primer_prompt = PromptTemplate.from_template(\n",
    "    \"Explica brevemente el concepto de {tema}.\"\n",
    ")\n",
    "\n",
    "# Segundo paso: generar aplicación educativa\n",
    "segundo_prompt = PromptTemplate.from_template(\n",
    "    \"Propón una aplicación educativa del siguiente concepto: {concepto}.\"\n",
    ")\n",
    "\n",
    "# Definir la secuencia con el nuevo sistema de Runnables\n",
    "chain = (\n",
    "    primer_prompt\n",
    "    | llm\n",
    "    | (lambda output: {\"concepto\": output.content})\n",
    "    | segundo_prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# Ejecutar la cadena completa\n",
    "resultado = chain.invoke({\"tema\": \"realidad aumentada\"})\n",
    "print(resultado.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Aplicación Educativa: \"ExplorAR\" - Plataforma de Aprendizaje Interactivo con Realidad Aumentada**\n",
      "\n",
      "**Descripción General:**\n",
      "ExplorAR es una aplicación educativa que utiliza la realidad aumentada para enriquecer el aprendizaje en diversas materias, como ciencias, historia, matemáticas y arte. A través de la superposición de información digital sobre objetos y lugares del mundo real, los estudiantes pueden interactuar con contenido educativo de manera dinámica y envolvente.\n",
      "\n",
      "**Características Principales:**\n",
      "\n",
      "1. **Exploraciones de Campo:**\n",
      "   - Los estudiantes pueden utilizar la aplicación en excursiones o en el aula para escanear objetos, lugares o imágenes. Al hacerlo, la aplicación proporciona información adicional, como datos históricos, descripciones científicas, o visualizaciones interactivas.\n",
      "   - Por ejemplo, al escanear una planta, los estudiantes pueden ver su estructura celular en 3D, escuchar datos sobre su hábitat, y aprender sobre su fotosíntesis.\n",
      "\n",
      "2. **Lecciones Interactivas:**\n",
      "   - Los docentes pueden crear lecciones interactivas donde los estudiantes pueden ver modelos 3D de conceptos complejos. Por ejemplo, en una clase de anatomía, los estudiantes pueden ver un modelo del cuerpo humano y explorar sus sistemas (circulatorio, digestivo, etc.) mediante la realidad aumentada.\n",
      "   - Los estudiantes pueden interactuar con estos modelos, girándolos y acercándose para obtener información más detallada.\n",
      "\n",
      "3. **Juegos Educativos:**\n",
      "   - La aplicación incluye juegos de preguntas y respuestas que utilizan la RA. Por ejemplo, los estudiantes pueden buscar objetos en su entorno real que correspondan a pistas dadas por la aplicación. Al encontrar y escanear el objeto correcto, reciben puntos y pueden desbloquear información adicional o desafíos.\n",
      "   - Esto fomenta el aprendizaje activo y la participación, además de hacer que el aprendizaje sea más divertido.\n",
      "\n",
      "4. **Creación de Proyectos:**\n",
      "   - Los estudiantes pueden crear sus propios proyectos utilizando la aplicación. Por ejemplo, pueden investigar un tema y luego crear una presentación en RA que incluya imágenes, videos y modelos 3D que se superpongan a su entorno.\n",
      "   - Esto les permite desarrollar habilidades de investigación, creatividad y presentación.\n",
      "\n",
      "5. **Colaboración y Compartición:**\n",
      "   - La aplicación permite a los estudiantes colaborar en proyectos y compartir sus creaciones con sus compañeros a través de una plataforma en línea. Esto fomenta el trabajo en equipo y el aprendizaje colaborativo.\n",
      "   - Los docentes pueden revisar y dar retroalimentación sobre los proyectos presentados.\n",
      "\n",
      "**Beneficios:**\n",
      "- **Aprendizaje Activo:** Los estudiantes participan de manera activa en su proceso de aprendizaje, lo que mejora la retención de información.\n",
      "- **Visualización de Conceptos Complejos:** La RA ayuda a descomponer conceptos difíciles en elementos visuales y tangibles.\n",
      "- **Fomento de la Curiosidad:** La interactividad y el juego estimulan la curiosidad y el deseo de aprender más.\n",
      "- **Adaptabilidad:** La aplicación puede adaptarse a diferentes niveles educativos y estilos de aprendizaje.\n",
      "\n",
      "**Conclusión:**\n",
      "ExplorAR representa una innovadora forma de integrar la realidad aumentada en el aula, transformando la manera en que los estudiantes interactúan con el conocimiento y fomentando un aprendizaje más profundo y significativo.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "# 1) LLM (usa tu OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# 2) Paso 1: explicar brevemente el concepto de {tema}\n",
    "primer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica brevemente el concepto de {tema}.\"\n",
    ")\n",
    "primer_paso = primer_prompt | llm | to_str\n",
    "# `primer_paso` produce un string, por ejemplo: \"La realidad aumentada es ...\"\n",
    "\n",
    "# 3) Paso 2: proponer una aplicación educativa usando la salida del paso 1 como {concepto}\n",
    "segundo_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Propón una aplicación educativa del siguiente concepto: {concepto}.\"\n",
    ")\n",
    "segundo_paso = segundo_prompt | llm | to_str\n",
    "\n",
    "# 4) Encadenar: mapear la entrada {tema} al primer paso, y su salida a {concepto} del segundo\n",
    "cadena_secuencial = {\"concepto\": primer_paso} | segundo_paso\n",
    "\n",
    "# 5) Ejecutar la cadena completa\n",
    "resultado = cadena_secuencial.invoke({\"tema\": \"realidad aumentada\"})\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! Encantado de ayudarte. ¿En qué puedo asistirte hoy en relación a la informática?\n",
      "Claro, aquí tienes algunas ideas para introducir la inteligencia artificial (IA) a tus estudiantes:\n",
      "\n",
      "1. **Conceptos Básicos**: Comienza con una introducción a la IA, explicando qué es, su historia y sus aplicaciones en la vida cotidiana. Utiliza ejemplos como asistentes virtuales (Siri, Alexa) y recomendaciones de películas o música.\n",
      "\n",
      "2. **Tipos de IA**: Explica las diferencias entre IA débil (específica para tareas) y IA fuerte (que puede razonar y aprender como un humano). \n",
      "\n",
      "3. **Lenguaje Natural y Aprendizaje Automático**: Introduce conceptos de procesamiento de lenguaje natural (NLP) y aprendizaje automático (machine learning). Puedes usar herramientas como Google Teachable Machine para mostrar cómo se entrena a un modelo.\n",
      "\n",
      "4. **Proyectos Prácticos**: Anima a los estudiantes a realizar proyectos simples. Por ejemplo, crear un chatbot básico o un modelo de clasificación de imágenes usando plataformas como Scratch o Python con bibliotecas como TensorFlow o Keras.\n",
      "\n",
      "5. **Ética en IA**: Discute las implicaciones éticas y sociales de la IA, como la privacidad, sesgos algorítmicos y el futuro del trabajo.\n",
      "\n",
      "6. **Recursos Interactivos**: Utiliza recursos en línea como cursos de plataformas educativas (Coursera, edX) o tutoriales en YouTube para complementar las lecciones.\n",
      "\n",
      "7. **Invitados Especiales**: Si es posible, invita a profesionales del campo de la IA para que compartan su experiencia y respondan preguntas.\n",
      "\n",
      "8. **Fomentar la Curiosidad**: Anima a los estudiantes a investigar y presentar sobre diferentes aplicaciones de la IA en campos como la medicina, la agricultura o los videojuegos.\n",
      "\n",
      "Recuerda adaptar el contenido a la edad y nivel de conocimiento de tus estudiantes. ¡Buena suerte!\n",
      "Aquí tienes algunos ejemplos prácticos de IA que puedes usar en clase:\n",
      "\n",
      "1. **Chatbots**: Crea un chatbot simple utilizando plataformas como Chatbot.com o Dialogflow. Los estudiantes pueden diseñar conversaciones y ver cómo funciona la IA en la interacción.\n",
      "\n",
      "2. **Clasificación de Imágenes**: Utiliza Google Teachable Machine para que los estudiantes entrenen un modelo que clasifique imágenes (por ejemplo, distinguir entre diferentes tipos de frutas o animales).\n",
      "\n",
      "3. **Reconocimiento de Voz**: Implementa un proyecto simple con herramientas como SpeechRecognition en Python para que los estudiantes experimenten con el reconocimiento de voz y comandos.\n",
      "\n",
      "4. **Análisis de Sentimientos**: Usa una API de análisis de sentimientos (como la de IBM Watson o TextBlob en Python) para que los estudiantes analicen comentarios de redes sociales o reseñas de productos.\n",
      "\n",
      "5. **Juegos con IA**: Introduce juegos que utilizan IA, como \"Akinator\", donde los estudiantes pueden ver cómo la IA adivina un personaje a partir de preguntas.\n",
      "\n",
      "6. **Generación de Arte**: Utiliza herramientas como DeepArt o DALL-E para que los estudiantes experimenten con la generación de imágenes a partir de descripciones textuales.\n",
      "\n",
      "7. **Predicción de Datos**: Enseña a los estudiantes a usar un conjunto de datos simple (como el de Titanic) y a aplicar algoritmos de aprendizaje automático para hacer predicciones.\n",
      "\n",
      "8. **Asistentes Virtuales**: Demuestra cómo funcionan los asistentes virtuales (como Google Assistant) y permite que los estudiantes interactúen con ellos, planteando preguntas o dando comandos.\n",
      "\n",
      "9. **Proyectos de Programación**: Si tus estudiantes tienen conocimientos de programación, pueden crear un programa simple que use un modelo de IA preentrenado, como un clasificador de texto.\n",
      "\n",
      "10. **Debates sobre Ética**: Organiza un debate sobre un tema ético relacionado con la IA, como el uso de algoritmos en la toma de decisiones o la privacidad de los datos.\n",
      "\n",
      "Estos ejemplos no solo son educativos, sino que también fomentan la creatividad y el pensamiento crítico en tus estudiantes. ¡Espero que te sean útiles!\n"
     ]
    }
   ],
   "source": [
    "# Instalar si hace falta:\n",
    "# %pip install -U langchain langchain-openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM (requiere OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# Prompt con hueco para el historial\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Eres un asistente educativo claro y conciso.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),      # ← aquí va la memoria\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Cadena base\n",
    "chain = prompt | llm | to_str\n",
    "\n",
    "# Memoria simple como lista de mensajes\n",
    "history: list = []\n",
    "\n",
    "def chat(user_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Envía un turno del usuario, usa el historial y actualiza la memoria\n",
    "    con el par (usuario, asistente).\n",
    "    \"\"\"\n",
    "    global history\n",
    "    # Ejecutar la cadena inyectando el historial actual\n",
    "    answer = chain.invoke({\"input\": user_text, \"chat_history\": history})\n",
    "    # Actualizar memoria (guardar los dos mensajes)\n",
    "    history += [HumanMessage(content=user_text), AIMessage(content=answer)]\n",
    "    return answer\n",
    "\n",
    "# --- Ejemplo de uso (tres turnos) ---\n",
    "print(chat(\"Hola, soy un profesor de informática.\"))\n",
    "print(chat(\"¿Puedes explicarme cómo introducir IA a mis estudiantes?\"))\n",
    "print(chat(\"¿Qué ejemplos prácticos puedo usar en la clase?\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
